---
layout: default
title: "Learning Expressive Quadrupedal Locomotion Guided by Kinematic Trajectory Generator"
---


<center><h1>{{ page.title }}</h1></center>

<td>
	<center>
		2023<br>
		<br>
		<nobr>Arnaud Klipfel (1) </nobr> &emsp;&emsp;
		<br>
		<nobr>(1) Georgia Institute of Tecnology</nobr> &emsp;&emsp;
		<!-- <img style="vertical-align:middle" src="a1_goalkeeping_teaser.png"  width="100%" height="inherit"/>		 -->
	</center>
</td>

<br>
	
<td>
	<hr>
	<h3 style="margin-bottom:10px;">Abstract</h3>
	Biological quadrupedal systems exhibit a wider range of locomotion skills. In Robotics, quadrupedal systems only exhibit a limited range of locomotion skills. They can be very robust for a single locomotion task, and state-of-the-art algorithms have been designed for walking gaits or use individual policies trained for a single skill. This thesis aimed to study the design of an expressive locomotion controller (different locomotion skills in one policy) for a quadrupedal robot. Different approaches based on Deep Reinforcement Learning have been studied for their recent successes in Robotics and Computer animation. A reference-free and a reference-based approach using solely reward shaping, i.e. specification of the motion through the reward, have been implemented. They produced walking gaits in simulation. Yet, the motions produced by the reference-based approach had limited footstep height and balance issues. The reference-free approach had higher footsteps and fewer base oscillations. Yet, both approaches are hard to adapt when it comes to expressiveness since the motion specification is solely done through reward shaping, which is not intuitive. Finally, inspired by works in computer animation and robotics, an approach based on motion clips for motion specification and general motion tracking has been implemented and produced more natural motions in simulation, i.e. higher footsteps, bigger strides, more base stability hard to generate using reward shaping.
</td>

<td>
	<h3> Thesis: [<a href="KLIPFEL-THESIS-2022.pdf">PDF</a>] &nbsp; &nbsp; &nbsp; Georgia Tech Library: [<a href="https://smartech.gatech.edu/handle/1853/69999">link</a>] </h3>
</td>

<tr>
	<center>
		<h3 style="margin-bottom:10px;">Hardware deployment of a reference-free walking policy</h3>
		<!-- <video width="1440"  height="1080" controls>
  			<source src="IMG_0118.MOV" type="video/MOV">
		</video> -->
<!-- 		<embed width="1440"  height="1080">
  			<source src="IMG_0118.MOV">
		</embed> -->
		<video src="IMG_0118.MOV" controls>
		</video>
	</center>

<!-- 		<center>
			<h3 style="margin-bottom:10px;">Hardware deployment of a reference-free walking policy</h3>
			<iframe width="720" src="IMG_0118.MOV" frameborder="0" allowfullscreen></iframe>
		</center>	
</tr> -->
	
<br>
<br>

<!-- <h3 style="margin-bottom:0px;">Bibtex</h3>
<pre>
@article{
	2023AKlipfel-SingleScalableMotionImitation,
	url = {https://arxiv.org/abs/2210.04435},
	author = {Huang, Xiaoyu and Li, Zhongyu and Xiang, Yanzhen and Ni, Yiming and Chi, Yufeng and Li, Yunhao and Yang, Lizhi and Peng, Xue Bin and Sreenath, Koushil},
	keywords = {Robotics (cs.RO), Artificial Intelligence (cs.AI), Systems and Control (eess.SY), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
	title = {Creating a Dynamic Quadrupedal Robotic Goalkeeper with Reinforcement Learning},
	publisher = {arXiv},
	year = {2022},
	copyright = {arXiv.org perpetual, non-exclusive license}
}
</pre> -->